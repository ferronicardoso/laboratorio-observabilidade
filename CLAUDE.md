# CLAUDE.md

Este arquivo fornece orientaÃ§Ãµes ao Claude Code ao trabalhar com cÃ³digo neste repositÃ³rio.

---

## ğŸ”¬ Sobre o Projeto

LaboratÃ³rio educacional de observabilidade com Stack Grafana (Prometheus, Loki, Alloy, Grafana, Tempo) instrumentando aplicaÃ§Ãµes em 4 linguagens (.NET, Python, Java, TypeScript/Node.js).

**Stack:**
- **Observabilidade**: Grafana, Prometheus, Loki, Tempo 2.9.1, Alloy, Node/Windows/DB Exporters
- **AplicaÃ§Ãµes**: .NET API, Python FastAPI, Java Spring Boot, Next.js, Angular, Nginx
- **Bancos**: PostgreSQL (Python), SQL Server (.\NET), MySQL (Java)
- **Infraestrutura**: Docker Compose

---

## ğŸš€ Comandos Essenciais

### Docker & Desenvolvimento

```bash
# Subir/parar stack
docker compose up -d
docker compose down

# Rebuild especÃ­fico
docker compose up -d --build <service-name>

# Ver logs
docker logs <container-name>
docker logs -f <container-name>  # follow

# Status
docker compose ps
```

### URLs Principais

- **Grafana**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9090
- **Tempo**: http://localhost:3200
- **.NET API**: http://localhost:5000
- **Python API**: http://localhost:8001
- **Java API**: http://localhost:8002
- **Next.js**: http://localhost:3001
- **Angular**: http://localhost:4200
- **Nginx**: http://localhost:8080
- **PostgreSQL**: localhost:5432 (labuser/labpass)
- **SQL Server**: localhost:1433 (sa/YourStrong!Passw0rd)
- **MySQL**: localhost:3306 (labuser/labpass)

### Gerar TrÃ¡fego para Testes

```bash
# .NET API
for i in {1..50}; do curl -s http://localhost:5000/api/products > /dev/null; done

# Python API
curl -X POST http://localhost:8001/items -H "Content-Type: application/json" -d '{"name":"Test","description":"Item","price":100}'

# Java API
curl -X POST http://localhost:8002/api/products -H "Content-Type: application/json" -d '{"name":"Mouse","price":250,"stock":10}'

# Traces (produtos com DB)
for i in {1..10}; do
  curl -s "http://localhost:5000/api/products?page=$((RANDOM % 10 + 1))&pageSize=5" > /dev/null
  sleep 0.2
done
```

---

## ğŸ—ï¸ Arquitetura

### Estrutura de DiretÃ³rios

```
lab-observabilidade/
â”œâ”€â”€ apps/                          # AplicaÃ§Ãµes
â”‚   â”œâ”€â”€ dotnet-api/               # .NET + OpenTelemetry
â”‚   â”œâ”€â”€ python-api/               # Python + OpenTelemetry
â”‚   â”œâ”€â”€ java-api/                 # Java + Micrometer
â”‚   â”œâ”€â”€ nextjs-app/               # Next.js + prom-client
â”‚   â”œâ”€â”€ angular-app/              # Angular + Faro SDK
â”‚   â””â”€â”€ nginx/
â”œâ”€â”€ observability/
â”‚   â”œâ”€â”€ prometheus/prometheus.yml
â”‚   â”œâ”€â”€ loki/loki-config.yml
â”‚   â”œâ”€â”€ alloy/config.alloy
â”‚   â”œâ”€â”€ tempo/tempo-config.yml
â”‚   â”œâ”€â”€ grafana/provisioning/
â”‚   â”‚   â”œâ”€â”€ datasources/
â”‚   â”‚   â””â”€â”€ dashboards/json/      # Dashboards provisionados
â”‚   â”œâ”€â”€ mysql-exporter/.my.cnf
â”‚   â””â”€â”€ alertmanager/alertmanager.yml
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ docs/                          # DocumentaÃ§Ã£o adicional
```

### Fluxo de Dados

**MÃ©tricas (Pull):**
1. Apps expÃµem `/metrics` â†’ Prometheus scrape (15s) â†’ Grafana query

**Logs (Push):**
1. Apps geram logs â†’ Alloy coleta â†’ Loki armazena â†’ Grafana query

**Traces (Push):**
1. Apps geram spans â†’ Alloy OTLP â†’ Tempo armazena â†’ Grafana visualiza
2. Tempo gera service graph metrics â†’ Prometheus (remote_write)

---

## ğŸ”§ InstrumentaÃ§Ã£o por Linguagem

### .NET API (OpenTelemetry)
- SDK: `OpenTelemetry.Extensions.Hosting`, `OpenTelemetry.Exporter.Prometheus.AspNetCore`
- Spans automÃ¡ticos: HTTP, Entity Framework Core (SQL queries)
- Endpoint: `/metrics`
- Traces: OTLP para Alloy (porta 4317 gRPC)

### Python API (OpenTelemetry)
- SDK: `opentelemetry-sdk`, `opentelemetry-instrumentation-fastapi`
- Endpoint: `/metrics`

### Java API (Micrometer)
- SDK: `micrometer-registry-prometheus` (Spring Boot Actuator)
- Endpoint: `/actuator/prometheus`

### Next.js (prom-client)
- Biblioteca: `prom-client`
- Endpoint: `/api/metrics`

### Angular (Grafana Faro)
- SDK: `@grafana/faro-web-sdk`
- Push para Alloy (porta 12347)
- Captura: Core Web Vitals, erros JS, navegaÃ§Ã£o

---

## ğŸ” Distributed Tracing

### Grafana Tempo v2.9.1

**âš ï¸ CRÃTICO - Bug na v2.10.0:**
- VersÃ£o 2.10.0 tem bug onde `ingester` nÃ£o inicializa em modo monolithic
- Erro: "InstancesCount <= 0"
- **Usar v2.9.1** (recomendada) ou 2.6.0, 2.7.x, 2.8.x

**Config Importante:**
- OTLP endpoints devem ser `0.0.0.0:4317` (nÃ£o `127.0.0.1`)
- Prometheus precisa de `--web.enable-remote-write-receiver`
- Service graph requer `metrics_generator` com `remote_write` configurado

**Visualizar Traces:**
```traceql
# âš ï¸ USAR resource.service.name (NÃƒO service.name)
{ resource.service.name="dotnet-api" }
{ resource.service.name="dotnet-api" && span.db.statement != nil }
{ resource.service.name="dotnet-api" && duration > 100ms }
```

### PostgreSQL com 1000 Produtos
- .NET API conecta ao PostgreSQL com dados prÃ©-carregados
- Traces incluem SQL queries completas (Entity Framework Core)
- Endpoints: GET/POST/PUT/DELETE /api/products

---

## ğŸ¯ Service Level Objectives (SLOs)

Todos os SLOs medidos em janela de **30 dias**:

| API | SLI | Target |
|-----|-----|--------|
| .NET/Python/Java | Availability | â‰¥ 99.9% (requisiÃ§Ãµes 2xx) |
| .NET/Python/Java | Latency P95 | < 200ms |
| .NET/Python/Java | Error Rate | < 0.1% (requisiÃ§Ãµes 5xx) |

**Dashboard:** `slo-dashboard.json`
- Current SLI values (stat panels com cores)
- Error Budget Remaining (gauge 0-100%)
- Burn Rate (1h) - velocidade de consumo do budget

**InterpretaÃ§Ã£o Burn Rate:**
- 1.0 = OK (taxa esperada)
- 5.0 = âš ï¸ Alerta (5x mais rÃ¡pido)
- 10.0 = ğŸš¨ CrÃ­tico (10x mais rÃ¡pido)

**Doc completa:** `docs/slo.md`

---

## ğŸ—„ï¸ Database Monitoring (Resumo)

### PostgreSQL (porta 9187)
- Exporter: `quay.io/prometheuscommunity/postgres-exporter`
- MÃ©tricas principais: `pg_up`, `pg_stat_database_*`, `pg_stat_activity_count`
- Dashboard: `postgresql.json`

### SQL Server (porta 4000)
- Exporter: `awaragi/prometheus-mssql-exporter`
- MÃ©tricas principais: `mssql_up`, `mssql_buffer_cache_hit_ratio`, `mssql_connections`
- Dashboard: `mssql.json`

### MySQL (porta 9104)
- Exporter: `prom/mysqld-exporter`
- Config: `observability/mysql-exporter/.my.cnf`
- MÃ©tricas principais: `mysql_up`, `mysql_global_status_*`
- Dashboard: `mysql.json`

**Ver mÃ©tricas:**
```bash
curl http://localhost:9187/metrics  # PostgreSQL
curl http://localhost:4000/metrics  # SQL Server
curl http://localhost:9104/metrics  # MySQL
```

---

## âš ï¸ Problemas Conhecidos CRÃTICOS

### 1. WSL2 + Filesystem 9p
**Problema:** Node Exporter nÃ£o coleta mÃ©tricas de disco no WSL2 (filesystem 9p incompatÃ­vel)

**SoluÃ§Ã£o:**
- MÃ©tricas `node_filesystem_*` NÃƒO disponÃ­veis no dashboard WSL
- Usar dashboard "HOST Windows + IIS" para mÃ©tricas de disco
- Outras mÃ©tricas (CPU, memÃ³ria, rede) funcionam normalmente

**Config aplicada:**
```yaml
command:
  - '--collector.filesystem.fs-types-exclude=^(autofs|...|9p)$$'
```

### 2. Queries de CPU no WSL2
**Problema:** `rate()` retorna valores > 100% no WSL2

**SoluÃ§Ã£o:** Usar `irate()` ao invÃ©s de `rate()`:
```promql
# âœ… Correto
100 - (avg(irate(node_cpu_seconds_total{mode="idle",job="node-exporter-linux"}[5m])) * 100)

# âŒ Pode retornar > 100%
100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
```

### 3. Grafana Tempo v2.10.0
**Problema:** Ingester nÃ£o inicializa em modo monolithic

**SoluÃ§Ã£o:** Usar v2.9.1 (recomendada) ou anteriores

### 4. Labels Diferentes (Loki vs Prometheus)
**Loki:** `{container="dotnet-api"}` ou `{job="nginx"}`
**Prometheus:** `{job="dotnet-api"}` ou `{instance="dotnet-api:5000"}`

---

## ğŸ“Š Dashboards Provisionados

Todos em `observability/grafana/provisioning/dashboards/json/`:

| Dashboard | Arquivo | DescriÃ§Ã£o |
|-----------|---------|-----------|
| Multi-Language Overview | `multi-language-overview.json` | Todas as APIs |
| APIs - Logs Consolidados | `apis-logs.json` | Logs centralizados |
| .NET/Python/Java/Next.js API | `{nome}-api.json` | Por aplicaÃ§Ã£o |
| Angular RUM | `angular-app.json` | Real User Monitoring |
| PostgreSQL/MySQL/SQL Server | `performance-{db}.json` | Database monitoring |
| SLO Dashboard | `slo-dashboard.json` | Service Level Objectives |
| WSL/Windows | `linux.json`, `windows.json` | Host monitoring |
| Alertas | `alerts.json` | Dashboard de alertas |

**Modificar dashboards:**
1. Editar `.json` em `observability/grafana/provisioning/dashboards/json/`
2. Reiniciar Grafana: `docker compose restart grafana`
3. âš ï¸ MudanÃ§as na UI do Grafana sÃ£o PERDIDAS ao reiniciar

---

## ğŸ” ConvenÃ§Ãµes

### Commits (Conventional Commits)
```
feat(api): adicionar endpoint de estatÃ­sticas
fix(docker): corrigir erro ao buildar Next.js
docs(readme): adicionar troubleshooting
refactor(metrics): extrair lÃ³gica para service
```

### Dashboards
**Naming:**
- Arquivos: `<nome>-<tipo>.json`
- TÃ­tulos: `[APP/SERVIÃ‡O] - [DescriÃ§Ã£o]`
- UIDs: `<nome>-<tipo>-monitoring`

**Estrutura:**
1. Primeira linha: Status, gauges, stats (altura 7-8)
2. Linhas seguintes: Time series (altura 8)
3. Refresh: `10s` para APIs
4. Time range: `now-30m` to `now`

### Docker
- Usar Alpine quando possÃ­vel
- Multi-stage builds
- `.dockerignore` em todos os projetos
- Health checks quando aplicÃ¡vel
- Restart policy: `unless-stopped` para serviÃ§os crÃ­ticos

---

## ğŸ“š Conceitos Importantes

### Queries Essenciais

**PromQL:**
```promql
# RequisiÃ§Ãµes/s
rate(http_server_request_duration_seconds_count{job="dotnet-api"}[1m])

# CPU Linux (usar irate no WSL2)
100 - (avg(irate(node_cpu_seconds_total{mode="idle",job="node-exporter-linux"}[5m])) * 100)
```

**LogQL:**
```logql
# Logs do container
{container="dotnet-api"}

# Busca texto
{container="dotnet-api"} |= "error"

# Taxa de logs
rate({container="python-api"}[5m])
```

**TraceQL:**
```traceql
# Service (usar resource.service.name)
{ resource.service.name="dotnet-api" }

# Com SQL queries
{ resource.service.name="dotnet-api" && span.db.statement != nil }

# Lentos ou com erro
{ resource.service.name="dotnet-api" && duration > 100ms }
{ resource.service.name="dotnet-api" && status = error }
```

---

<!-- BACKLOG.MD GUIDELINES START -->
# Instructions for the usage of Backlog.md CLI Tool

## Backlog.md: Comprehensive Project Management Tool via CLI

### Assistant Objective

Efficiently manage all project tasks, status, and documentation using the Backlog.md CLI, ensuring all project metadata
remains fully synchronized and up-to-date.

### Core Capabilities

- âœ… **Task Management**: Create, edit, assign, prioritize, and track tasks with full metadata
- âœ… **Search**: Fuzzy search across tasks, documents, and decisions with `backlog search`
- âœ… **Acceptance Criteria**: Granular control with add/remove/check/uncheck by index
- âœ… **Board Visualization**: Terminal-based Kanban board (`backlog board`) and web UI (`backlog browser`)
- âœ… **Git Integration**: Automatic tracking of task states across branches
- âœ… **Dependencies**: Task relationships and subtask hierarchies
- âœ… **Documentation & Decisions**: Structured docs and architectural decision records
- âœ… **Export & Reporting**: Generate markdown reports and board snapshots
- âœ… **AI-Optimized**: `--plain` flag provides clean text output for AI processing

### Why This Matters to You (AI Agent)

1. **Comprehensive system** - Full project management capabilities through CLI
2. **The CLI is the interface** - All operations go through `backlog` commands
3. **Unified interaction model** - You can use CLI for both reading (`backlog task 1 --plain`) and writing (
   `backlog task edit 1`)
4. **Metadata stays synchronized** - The CLI handles all the complex relationships

### Key Understanding

- **Tasks** live in `backlog/tasks/` as `task-<id> - <title>.md` files
- **You interact via CLI only**: `backlog task create`, `backlog task edit`, etc.
- **Use `--plain` flag** for AI-friendly output when viewing/listing
- **Never bypass the CLI** - It handles Git, metadata, file naming, and relationships

---

# âš ï¸ CRITICAL: NEVER EDIT TASK FILES DIRECTLY. Edit Only via CLI

**ALL task operations MUST use the Backlog.md CLI commands**

- âœ… **DO**: Use `backlog task edit` and other CLI commands
- âœ… **DO**: Use `backlog task create` to create new tasks
- âœ… **DO**: Use `backlog task edit <id> --check-ac <index>` to mark acceptance criteria
- âŒ **DON'T**: Edit markdown files directly
- âŒ **DON'T**: Manually change checkboxes in files
- âŒ **DON'T**: Add or modify text in task files without using CLI

**Why?** Direct file editing breaks metadata synchronization, Git tracking, and task relationships.

---

## 1. Source of Truth & File Structure

### ğŸ“– **UNDERSTANDING** (What you'll see when reading)

- Markdown task files live under **`backlog/tasks/`** (drafts under **`backlog/drafts/`**)
- Files are named: `task-<id> - <title>.md` (e.g., `task-42 - Add GraphQL resolver.md`)
- Project documentation is in **`backlog/docs/`**
- Project decisions are in **`backlog/decisions/`**

### ğŸ”§ **ACTING** (How to change things)

- **All task operations MUST use the Backlog.md CLI tool**
- This ensures metadata is correctly updated and the project stays in sync
- **Always use `--plain` flag** when listing or viewing tasks for AI-friendly text output

---

## 2. Common Mistakes to Avoid

### âŒ **WRONG: Direct File Editing**

```markdown
# DON'T DO THIS:
1. Open backlog/tasks/task-7 - Feature.md in editor
2. Change "- [ ]" to "- [x]" manually
3. Add notes directly to the file
4. Save the file
```

### âœ… **CORRECT: Using CLI Commands**

```bash
# DO THIS INSTEAD:
backlog task edit 7 --check-ac 1  # Mark AC #1 as complete
backlog task edit 7 --notes "Implementation complete"  # Add notes
backlog task edit 7 -s "In Progress" -a @agent-k  # Change status and assign
```

---

## 3. Understanding Task Format (Read-Only Reference)

âš ï¸ **FORMAT REFERENCE ONLY** - Never edit task files directly! Use CLI commands.

### How to Modify Each Section

| What You Want to Change | CLI Command to Use |
|-------------------------|-------------------|
| Title | `backlog task edit 42 -t "New Title"` |
| Status | `backlog task edit 42 -s "In Progress"` |
| Assignee | `backlog task edit 42 -a @sara` |
| Labels | `backlog task edit 42 -l backend,api` |
| Description | `backlog task edit 42 -d "New description"` |
| Add AC | `backlog task edit 42 --ac "New criterion"` |
| Check AC #1 | `backlog task edit 42 --check-ac 1` |
| Uncheck AC #2 | `backlog task edit 42 --uncheck-ac 2` |
| Remove AC #3 | `backlog task edit 42 --remove-ac 3` |
| Add Plan | `backlog task edit 42 --plan "1. Step one\n2. Step two"` |
| Add Notes | `backlog task edit 42 --notes "What I did"` |
| Append Notes | `backlog task edit 42 --append-notes "Another note"` |

---

## 4. Implementing Tasks Workflow

### Step 1: Start Work
```bash
# Assign yourself and set to In Progress
backlog task edit 42 -s "In Progress" -a @myself
```

### Step 2: Create Implementation Plan
```bash
# Think about HOW to solve the task
backlog task edit 42 --plan "1. Research\n2. Implement\n3. Test"
```

### Step 3: Share Plan with User
Share the plan and wait for approval before coding.

### Step 4: Implement
Write code, test, and mark acceptance criteria as complete:
```bash
backlog task edit 42 --check-ac 1 --check-ac 2
```

### Step 5: Add Implementation Notes
```bash
backlog task edit 42 --notes "Implemented using pattern X, modified files Y and Z"
```

### Step 6: Mark as Done
```bash
backlog task edit 42 -s Done
```

---

## 5. Quick Reference: Common Commands

```bash
# List tasks
backlog task list --plain
backlog task list -s "To Do" --plain

# View task
backlog task 42 --plain

# Search
backlog search "auth" --plain

# Create task
backlog task create "Task title" -d "Description" --ac "Criterion 1"

# Edit task
backlog task edit 42 -s "In Progress" -a @myself
backlog task edit 42 --check-ac 1
backlog task edit 42 --notes "Implementation complete"
```

---

## Remember: The Golden Rule

**ğŸ¯ If you want to change ANYTHING in a task, use `backlog task edit`**
**ğŸ“– Use CLI to read tasks, exceptionally READ task files directly, never WRITE to them**

Full help: `backlog --help`

<!-- BACKLOG.MD GUIDELINES END -->
