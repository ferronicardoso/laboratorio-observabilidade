# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

---

## üî¨ Sobre o Projeto

Este √© um **laborat√≥rio educacional de observabilidade** que demonstra conceitos modernos de monitoramento, logging e m√©tricas usando a Stack Grafana (Prometheus, Loki, Alloy, Grafana) com aplica√ß√µes em m√∫ltiplas linguagens (.NET, Python, Java, TypeScript).

**Stack:**
- **Observabilidade**: Grafana, Prometheus, Loki, Grafana Tempo, Grafana Alloy, Node Exporter, Windows Exporter
- **Aplica√ß√µes**: .NET API, Python FastAPI, Java Spring Boot, Next.js, Angular, Nginx
- **Banco de Dados**: PostgreSQL 18-alpine (1000 produtos para traces realistas)
- **Infraestrutura**: Docker + Docker Compose

---

## üöÄ Comandos Essenciais

### Executar o Projeto

```bash
# Subir toda a stack
docker compose up -d

# Verificar status dos containers
docker compose ps

# Ver logs de um servi√ßo espec√≠fico
docker logs <container-name>

# Parar a stack
docker compose down

# Rebuild de um servi√ßo espec√≠fico
docker compose up -d --build <service-name>

# Rebuild completo
docker compose down && docker compose up -d --build
```

### Acessar Interfaces

- **Grafana**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9090
- **Tempo**: http://localhost:3200 (API)
- **pgAdmin**: http://localhost:5050 (gerenciamento PostgreSQL)
- **Next.js**: http://localhost:3001
- **Angular**: http://localhost:4200
- **.NET API**: http://localhost:5000
- **Python API**: http://localhost:8001
- **Java API**: http://localhost:8002
- **Nginx**: http://localhost:8080
- **PostgreSQL**: localhost:5432 (banco de dados)

### Testar M√©tricas

```bash
# Verificar targets no Prometheus
curl -s http://localhost:9090/api/v1/targets | jq '.data.activeTargets[] | {job: .labels.job, health: .health}'

# Ver m√©tricas de uma aplica√ß√£o
curl http://localhost:5000/metrics  # .NET
curl http://localhost:8001/metrics  # Python
curl http://localhost:8002/actuator/prometheus  # Java

# Gerar tr√°fego para testes
for i in {1..50}; do curl -s http://localhost:5000/weatherforecast > /dev/null; done
```

### Queries √öteis

**PromQL (Prometheus):**
```promql
# Requisi√ß√µes por segundo
rate(http_server_request_duration_seconds_count{job="dotnet-api"}[1m])

# Uso de CPU do Windows
100 - (avg(rate(windows_cpu_time_total{mode="idle",job="node-exporter-windows"}[2m])) * 100)

# Uso de CPU do Linux
100 - (avg(irate(node_cpu_seconds_total{mode="idle",job="node-exporter-linux"}[5m])) * 100)
```

**LogQL (Loki):**
```logql
# Logs do Nginx
{job="nginx"}

# Logs de uma aplica√ß√£o espec√≠fica
{container="dotnet-api"}

# Taxa de logs
rate({container="python-api"}[1m])
```

**TraceQL (Tempo):**
```traceql
# Todos os traces de um servi√ßo
{ resource.service.name="dotnet-api" }

# Traces com queries SQL
{ resource.service.name="dotnet-api" && span.db.statement != nil }

# Traces com dura√ß√£o > 100ms
{ resource.service.name="dotnet-api" && duration > 100ms }

# Traces com erro
{ resource.service.name="dotnet-api" && status = error }
```

---

## üîç Distributed Tracing (Fase 2)

### Grafana Tempo v2.9.1

**‚ö†Ô∏è IMPORTANTE - Bug na vers√£o 2.10.0:**
A vers√£o 2.10.0 do Tempo tem um bug conhecido onde o m√≥dulo `ingester` n√£o √© inicializado em modo monolithic (single-binary), causando o erro "InstancesCount <= 0". Use a vers√£o **2.9.1** ou anteriores (2.6.0, 2.7.x, 2.8.x, 2.9.x) at√© que o bug seja corrigido.

**Vers√µes testadas e funcionais:**
- ‚úÖ v2.6.0 - funciona
- ‚úÖ v2.8.2 - funciona
- ‚úÖ v2.9.1 - funciona (recomendada)
- ‚ùå v2.10.0 - ingester n√£o inicializa

### Componentes de Tracing

**Stack de Tracing:**
- **Tempo 2.9.1**: Backend para armazenamento de traces
- **OpenTelemetry**: Instrumenta√ß√£o da API .NET
- **Grafana Alloy**: Coletor de traces (OTLP receiver)
- **PostgreSQL 18-alpine**: Banco de dados com 1000 produtos para queries realistas

**Fluxo de Dados:**
1. API .NET gera traces com OpenTelemetry SDK
2. Traces incluem spans HTTP, Entity Framework Core (SQL queries)
3. Alloy recebe traces via OTLP (portas 4317 gRPC / 4318 HTTP)
4. Alloy encaminha para Tempo
5. Tempo armazena traces e gera m√©tricas (service graphs, span metrics)
6. M√©tricas s√£o enviadas ao Prometheus via remote_write
7. Grafana consulta traces no Tempo e visualiza Service Graph

### Configura√ß√£o do Tempo

**Config m√≠nima para modo monolithic (`tempo-config.yml`):**
```yaml
stream_over_http_enabled: true

server:
  http_listen_port: 3200

distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317  # IMPORTANTE: 0.0.0.0, n√£o 127.0.0.1
        http:
          endpoint: 0.0.0.0:4318

ingester:
  lifecycler:
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
  max_block_duration: 5m

metrics_generator:
  registry:
    external_labels:
      source: tempo
      cluster: lab-observabilidade
  storage:
    path: /var/tempo/generator/wal
    remote_write:
      - url: http://prometheus:9090/api/v1/write
        send_exemplars: true

storage:
  trace:
    backend: local
    local:
      path: /var/tempo/blocks
    wal:
      path: /var/tempo/wal

overrides:
  defaults:
    metrics_generator:
      processors: [service-graphs, span-metrics]
```

**Configura√ß√£o do Prometheus:**
- Adicionar flag `--web.enable-remote-write-receiver` para aceitar m√©tricas do Tempo
- Tempo envia m√©tricas de service graphs e span metrics automaticamente

### Visualizar Traces no Grafana

**1. Grafana Explore:**
- URL: http://localhost:3000/explore
- Selecionar datasource "Tempo"

**2. Search (interface visual):**
- Service Name: `dotnet-api`
- Span Name: filtros opcionais
- Tags: `http.method`, `http.status_code`, etc.

**3. TraceQL (queries avan√ßadas):**
```traceql
# ‚ö†Ô∏è IMPORTANTE: usar resource.service.name, N√ÉO service.name
{ resource.service.name="dotnet-api" }
{ resource.service.name="dotnet-api" && span.db.statement != nil }
{ resource.service.name="dotnet-api" && duration > 100ms }
```

**4. Service Graph:**
- Visualiza√ß√£o do fluxo de requisi√ß√µes entre servi√ßos
- Mostra taxa de requisi√ß√µes, lat√™ncia e erros
- Requer m√©tricas do metrics_generator no Prometheus

**5. Correla√ß√£o com Logs:**
- Clicar em um span no trace
- Grafana busca logs correlacionados automaticamente via tags

### Instrumenta√ß√£o da API .NET

**Pacotes necess√°rios:**
```xml
<PackageReference Include="OpenTelemetry.Exporter.OpenTelemetryProtocol" Version="1.10.0" />
<PackageReference Include="OpenTelemetry.Instrumentation.AspNetCore" Version="1.10.0" />
<PackageReference Include="OpenTelemetry.Instrumentation.Http" Version="1.10.0" />
<PackageReference Include="OpenTelemetry.Instrumentation.EntityFrameworkCore" Version="1.0.0-beta.14" />
```

**Configura√ß√£o (`Program.cs`):**
```csharp
builder.Services.AddOpenTelemetry()
    .WithTracing(tracing =>
    {
        tracing
            .SetResourceBuilder(ResourceBuilder.CreateDefault()
                .AddService("dotnet-api", serviceVersion: "1.0.0"))
            .AddAspNetCoreInstrumentation(options =>
            {
                options.RecordException = true;
                options.EnrichWithHttpRequest = (activity, request) =>
                {
                    activity.SetTag("http.request.method", request.Method);
                    activity.SetTag("http.request.path", request.Path);
                };
            })
            .AddHttpClientInstrumentation()
            .AddEntityFrameworkCoreInstrumentation(options =>
            {
                options.SetDbStatementForText = true;
                options.EnrichWithIDbCommand = (activity, command) =>
                {
                    activity.SetTag("db.query", command.CommandText);
                };
            })
            .AddOtlpExporter(options =>
            {
                options.Endpoint = new Uri("http://alloy:4317");
                options.Protocol = OtlpExportProtocol.Grpc;
            });
    });
```

**Spans gerados automaticamente:**
- ‚úÖ HTTP requests (ASP.NET Core)
- ‚úÖ SQL queries (Entity Framework Core)
- ‚úÖ HTTP client calls
- ‚úÖ Exce√ß√µes (quando configurado)

**Atributos √∫teis nos traces:**
- `http.method`, `http.route`, `http.status_code`
- `db.statement` - SQL query completa
- `db.system`, `db.name` - informa√ß√µes do banco
- Dura√ß√£o de cada span em microssegundos

### Gerar Tr√°fego para Traces

```bash
# GET produtos (pagina√ß√£o + SQL queries)
for i in {1..10}; do
  curl -s "http://localhost:5000/api/products?page=$((RANDOM % 10 + 1))&pageSize=5" > /dev/null
  sleep 0.2
done

# GET por ID (queries SQL espec√≠ficas)
for i in {1..10}; do
  curl -s "http://localhost:5000/api/products/$((RANDOM % 1000 + 1))" > /dev/null
  sleep 0.2
done

# Count
for i in {1..5}; do
  curl -s "http://localhost:5000/api/products/count" > /dev/null
  sleep 0.2
done
```

### Troubleshooting Traces

**Traces n√£o aparecem no Grafana:**
1. Verificar se Tempo est√° rodando: `docker logs tempo | grep "starting module=ingester"`
2. Verificar se Alloy est√° encaminhando: `docker logs alloy | grep tempo`
3. Verificar endpoints OTLP: devem ser `0.0.0.0:4317` e n√£o `127.0.0.1`
4. Gerar tr√°fego na API para criar traces

**Service Graph vazio:**
1. Verificar se Prometheus aceita remote write: flag `--web.enable-remote-write-receiver`
2. Verificar se metrics_generator tem `remote_write` configurado
3. Aguardar 1-2 minutos ap√≥s gerar tr√°fego
4. Verificar m√©tricas no Prometheus: `curl http://localhost:9090/api/v1/label/__name__/values | grep traces_service_graph`

**Erro "InstancesCount <= 0":**
- Vers√£o 2.10.0 do Tempo est√° com bug
- Usar vers√£o 2.9.1 ou anterior

---

## üèóÔ∏è Arquitetura do Projeto

### Estrutura de Diret√≥rios

```
lab-observabilidade/
‚îú‚îÄ‚îÄ apps/                                    # Aplica√ß√µes monitoradas
‚îÇ   ‚îú‚îÄ‚îÄ dotnet-api/                         # API .NET com OpenTelemetry
‚îÇ   ‚îú‚îÄ‚îÄ python-api/                         # API Python com OpenTelemetry
‚îÇ   ‚îú‚îÄ‚îÄ java-api/                           # API Java com Micrometer
‚îÇ   ‚îú‚îÄ‚îÄ nextjs-app/                         # App Next.js com prom-client
‚îÇ   ‚îú‚îÄ‚îÄ angular-app/                        # App Angular com Grafana Faro
‚îÇ   ‚îî‚îÄ‚îÄ nginx/                              # Nginx como reverse proxy
‚îÇ
‚îú‚îÄ‚îÄ observability/                          # Stack de observabilidade
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prometheus.yml                  # Config de scrape targets
‚îÇ   ‚îú‚îÄ‚îÄ loki/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ loki-config.yml                # Config de armazenamento de logs
‚îÇ   ‚îú‚îÄ‚îÄ alloy/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.alloy                   # Config de coleta (logs + RUM)
‚îÇ   ‚îî‚îÄ‚îÄ grafana/
‚îÇ       ‚îî‚îÄ‚îÄ provisioning/                   # Configura√ß√£o autom√°tica
‚îÇ           ‚îú‚îÄ‚îÄ datasources/               # Prometheus + Loki
‚îÇ           ‚îî‚îÄ‚îÄ dashboards/                # Dashboards em JSON
‚îÇ               ‚îî‚îÄ‚îÄ json/
‚îÇ                   ‚îú‚îÄ‚îÄ apis-logs.json     # Logs consolidados
‚îÇ                   ‚îú‚îÄ‚îÄ linux.json         # Host Linux/WSL
‚îÇ                   ‚îú‚îÄ‚îÄ windows.json       # Host Windows + IIS
‚îÇ                   ‚îî‚îÄ‚îÄ [app]-*.json       # Dashboards por app
‚îÇ
‚îî‚îÄ‚îÄ docker-compose.yml                      # Orquestra√ß√£o completa
```

### Fluxo de Dados

**M√©tricas (Pull):**
1. Aplica√ß√µes exp√µem `/metrics` em formato Prometheus
2. Prometheus faz scrape a cada 15s (configurado em `prometheus.yml`)
3. Grafana consulta Prometheus via PromQL

**Logs (Push):**
1. Aplica√ß√µes geram logs no stdout/stderr
2. Alloy coleta via Docker logs API
3. Alloy adiciona labels (`container`, `job`) e envia para Loki
4. Grafana consulta Loki via LogQL

**RUM (Push):**
1. Angular app usa Grafana Faro SDK
2. SDK captura Core Web Vitals, erros, intera√ß√µes
3. Envia para Alloy via HTTP (porta 12347)
4. Alloy processa e envia para Loki

**Host Monitoring:**
- **Linux/WSL**: Node Exporter (porta 9100) ‚Üí Prometheus
- **Windows**: Windows Exporter (porta 9182) ‚Üí Prometheus

---

## üîß Componentes e Tecnologias

### Instrumenta√ß√£o por Linguagem

**API .NET (OpenTelemetry):**
- SDK: `OpenTelemetry.Extensions.Hosting`
- Exporters: `OpenTelemetry.Exporter.Prometheus.AspNetCore`
- M√©tricas autom√°ticas: HTTP, ASP.NET Core, Runtime (.NET GC)
- M√©tricas customizadas: `Meter` + `Counter`
- Endpoint: `/metrics`

**API Python (OpenTelemetry):**
- SDK: `opentelemetry-sdk`
- Instrumenta√ß√£o: `opentelemetry-instrumentation-fastapi`
- Exporter: `opentelemetry-exporter-prometheus`
- Endpoint: `/metrics`

**API Java (Micrometer):**
- SDK: `micrometer-registry-prometheus` (Spring Boot Actuator)
- M√©tricas autom√°ticas: HTTP, JVM, sistema
- Endpoint: `/actuator/prometheus`

**Next.js (prom-client):**
- Biblioteca: `prom-client`
- M√©tricas autom√°ticas: HTTP, Node.js runtime
- Endpoint: `/api/metrics`

**Angular (Grafana Faro):**
- SDK: `@grafana/faro-web-sdk`
- Captura: Core Web Vitals (LCP, FID, CLS), erros JS, navega√ß√£o
- Push para Alloy (porta 12347)

### Labels Importantes

**Loki:**
- `container`: nome do container Docker (ex: `dotnet-api`, `nginx`)
- `job`: identificador do servi√ßo (ex: `nginx`, `node-exporter-linux`)
- `type`: tipo de log (ex: `access`, `error`) - usado no Nginx

**Prometheus:**
- `job`: nome do job configurado em `prometheus.yml`
- `instance`: endere√ßo do target (ex: `dotnet-api:5000`)
- M√©tricas Windows: `job="node-exporter-windows"`
- M√©tricas Linux: `job="node-exporter-linux"`

---

## ‚ö†Ô∏è Problemas Conhecidos e Limita√ß√µes

### WSL2 e Filesystem 9p

O **Node Exporter Linux** n√£o consegue coletar m√©tricas de disco no WSL2 devido ao filesystem tipo 9p (Plan 9 Protocol).

**Solu√ß√£o aplicada:**
- Dashboard Linux (`linux.json`) tem painel "Disk Usage" substitu√≠do por mensagem informativa
- M√©tricas de disco do Windows devem ser consultadas no dashboard Windows

**Configura√ß√£o:**
```yaml
# docker-compose.yml - node-exporter-linux
command:
  - '--collector.filesystem.fs-types-exclude=^(autofs|...|9p)$$'
```

### Queries de CPU no WSL2

A fun√ß√£o `rate()` pode retornar valores incorretos no WSL2. Use `irate()` para queries de CPU:

```promql
# ‚úÖ Correto para WSL2
100 - (avg(irate(node_cpu_seconds_total{mode="idle",job="node-exporter-linux"}[5m])) * 100)

# ‚ùå Pode retornar valores > 100%
100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
```

### IIS Metrics

As m√©tricas do IIS no dashboard Windows s√≥ retornar√£o dados se o IIS estiver instalado e rodando no host Windows. Sem IIS, os pain√©is ficar√£o vazios (comportamento esperado).

### Logs vs M√©tricas

- **Loki** usa labels diferentes de Prometheus:
  - Loki: `{container="dotnet-api"}` ou `{job="nginx"}`
  - Prometheus: `{job="dotnet-api"}` ou `{instance="dotnet-api:5000"}`

---

## üìä Dashboards do Grafana

Todos os dashboards s√£o provisionados automaticamente em `observability/grafana/provisioning/dashboards/json/`:

| Dashboard | Arquivo | Descri√ß√£o |
|-----------|---------|-----------|
| APIs - Logs Consolidados | `apis-logs.json` | Logs de todas as APIs + Nginx |
| Multi-Language Overview | `multi-language-overview.json` | Vis√£o geral de todas as APIs |
| .NET API | `dotnet-api.json` | M√©tricas espec√≠ficas da API .NET |
| Python API | `python-api.json` | M√©tricas espec√≠ficas da API Python |
| Java API | `java-api.json` | M√©tricas espec√≠ficas da API Java |
| Next.js App | `nextjs-app.json` | M√©tricas espec√≠ficas do Next.js |
| Angular App | `angular-app.json` | RUM e Core Web Vitals |
| Nginx | `nginx.json` | M√©tricas do Nginx |
| WSL - Monitoramento do Sistema | `linux.json` | Monitoramento do WSL (Linux rodando no Windows) |
| HOST Windows + IIS | `windows.json` | Monitoramento do host Windows f√≠sico + IIS |

### Modificar Dashboards

**Op√ß√£o 1 - Via Grafana UI (tempor√°rio):**
1. Editar dashboard no Grafana
2. Exportar JSON (Share ‚Üí Export ‚Üí Save to file)
3. Copiar JSON para `observability/grafana/provisioning/dashboards/json/`
4. Reiniciar Grafana: `docker compose restart grafana`

**Op√ß√£o 2 - Editar JSON diretamente (permanente):**
1. Editar arquivo `.json` em `observability/grafana/provisioning/dashboards/json/`
2. Reiniciar Grafana: `docker compose restart grafana`

**IMPORTANTE:**
- Dashboards provisionados n√£o podem ser editados diretamente no Grafana UI
- Mudan√ßas feitas na UI s√£o perdidas ao reiniciar
- Sempre edite o JSON de origem

---

## üêõ Troubleshooting

### Container n√£o sobe

```bash
# Ver logs do container
docker logs <container-name>

# Verificar conflito de portas
docker compose ps
netstat -ano | findstr :<porta>  # Windows
lsof -i :<porta>  # Linux/macOS

# Rebuild for√ßado
docker compose down
docker compose up -d --build
```

### M√©tricas n√£o aparecem no Prometheus

```bash
# 1. Verificar se target est√° UP
curl http://localhost:9090/targets

# 2. Verificar se aplica√ß√£o est√° expondo m√©tricas
curl http://localhost:5000/metrics

# 3. Verificar configura√ß√£o do Prometheus
cat observability/prometheus/prometheus.yml

# 4. Restart do Prometheus
docker compose restart prometheus
```

### Logs n√£o aparecem no Loki

```bash
# 1. Verificar logs do Alloy
docker logs alloy

# 2. Testar query no Grafana Explore
{container="dotnet-api"}

# 3. Verificar se container est√° gerando logs
docker logs dotnet-api

# 4. Restart do Alloy
docker compose restart alloy
```

### Dashboard vazio no Grafana

1. Verificar se datasources est√£o configurados (Connections ‚Üí Data sources)
2. Verificar se Prometheus/Loki est√£o UP
3. Verificar queries no painel (Edit panel ‚Üí Query inspector)
4. Verificar se h√° dados no time range selecionado

---

## üîç Conven√ß√µes de C√≥digo

### Commits

Seguir [Conventional Commits](https://www.conventionalcommits.org/):
- `feat(api): adicionar endpoint de estat√≠sticas`
- `fix(docker): corrigir erro ao buildar Next.js`
- `docs(readme): adicionar troubleshooting`
- `refactor(metrics): extrair l√≥gica para service`

### Dashboards

**Naming convention:**
- Arquivos: `<nome>-<tipo>.json` (ex: `dotnet-api.json`, `apis-logs.json`)
- T√≠tulos: `[APP/SERVI√áO] - [Descri√ß√£o]` (ex: `.NET API - Dashboard`, `APIs - Logs Consolidados`)
- UIDs: `<nome>-<tipo>-monitoring` (ex: `dotnet-api-monitoring`, `host-monitoring`)

**Estrutura de pain√©is:**
1. Primeira linha: Status, gauges, stats (altura 7-8)
2. Linhas seguintes: Time series, gr√°ficos (altura 8)
3. Usar refresh: `10s` para dashboards de APIs
4. Usar time range: `now-30m` to `now` por padr√£o

### Docker

- Usar imagens Alpine quando poss√≠vel
- Multi-stage builds para otimiza√ß√£o
- `.dockerignore` em todos os projetos
- Health checks quando aplic√°vel
- Restart policy: `unless-stopped` para servi√ßos cr√≠ticos

---

## üìö Conceitos Importantes

### Os 3 Pilares da Observabilidade

1. **M√©tricas** - N√∫meros agregados (requisi√ß√µes/s, lat√™ncia, CPU)
2. **Logs** - Eventos textuais (erros, requisi√ß√µes HTTP, stack traces)
3. **Traces** - Caminho de requisi√ß√µes entre servi√ßos (n√£o implementado neste lab)

### Pull vs Push

- **Prometheus** = Pull-based (faz scrape das aplica√ß√µes)
- **Loki** = Push-based (Alloy envia logs para Loki)
- **Grafana Faro** = Push-based (SDK envia RUM para Alloy)

### PromQL B√°sico

```promql
# Counter - taxa de mudan√ßa
rate(metric_total[1m])

# Gauge - valor atual
metric_value

# Histogram - percentis
histogram_quantile(0.95, rate(metric_bucket[1m]))

# Agrega√ß√£o
sum by(job) (metric)
avg(metric)
max(metric) by (instance)
```

### LogQL B√°sico

```logql
# Filtro simples
{container="nginx"}

# M√∫ltiplos labels
{job="nginx", type="access"}

# Busca de texto
{container="dotnet-api"} |= "error"

# Taxa de logs
rate({container="python-api"}[5m])
```

---

<!-- BACKLOG.MD GUIDELINES START -->
# Instructions for the usage of Backlog.md CLI Tool

## Backlog.md: Comprehensive Project Management Tool via CLI

### Assistant Objective

Efficiently manage all project tasks, status, and documentation using the Backlog.md CLI, ensuring all project metadata
remains fully synchronized and up-to-date.

### Core Capabilities

- ‚úÖ **Task Management**: Create, edit, assign, prioritize, and track tasks with full metadata
- ‚úÖ **Search**: Fuzzy search across tasks, documents, and decisions with `backlog search`
- ‚úÖ **Acceptance Criteria**: Granular control with add/remove/check/uncheck by index
- ‚úÖ **Board Visualization**: Terminal-based Kanban board (`backlog board`) and web UI (`backlog browser`)
- ‚úÖ **Git Integration**: Automatic tracking of task states across branches
- ‚úÖ **Dependencies**: Task relationships and subtask hierarchies
- ‚úÖ **Documentation & Decisions**: Structured docs and architectural decision records
- ‚úÖ **Export & Reporting**: Generate markdown reports and board snapshots
- ‚úÖ **AI-Optimized**: `--plain` flag provides clean text output for AI processing

### Why This Matters to You (AI Agent)

1. **Comprehensive system** - Full project management capabilities through CLI
2. **The CLI is the interface** - All operations go through `backlog` commands
3. **Unified interaction model** - You can use CLI for both reading (`backlog task 1 --plain`) and writing (
   `backlog task edit 1`)
4. **Metadata stays synchronized** - The CLI handles all the complex relationships

### Key Understanding

- **Tasks** live in `backlog/tasks/` as `task-<id> - <title>.md` files
- **You interact via CLI only**: `backlog task create`, `backlog task edit`, etc.
- **Use `--plain` flag** for AI-friendly output when viewing/listing
- **Never bypass the CLI** - It handles Git, metadata, file naming, and relationships

---

# ‚ö†Ô∏è CRITICAL: NEVER EDIT TASK FILES DIRECTLY. Edit Only via CLI

**ALL task operations MUST use the Backlog.md CLI commands**

- ‚úÖ **DO**: Use `backlog task edit` and other CLI commands
- ‚úÖ **DO**: Use `backlog task create` to create new tasks
- ‚úÖ **DO**: Use `backlog task edit <id> --check-ac <index>` to mark acceptance criteria
- ‚ùå **DON'T**: Edit markdown files directly
- ‚ùå **DON'T**: Manually change checkboxes in files
- ‚ùå **DON'T**: Add or modify text in task files without using CLI

**Why?** Direct file editing breaks metadata synchronization, Git tracking, and task relationships.

---

## 1. Source of Truth & File Structure

### üìñ **UNDERSTANDING** (What you'll see when reading)

- Markdown task files live under **`backlog/tasks/`** (drafts under **`backlog/drafts/`**)
- Files are named: `task-<id> - <title>.md` (e.g., `task-42 - Add GraphQL resolver.md`)
- Project documentation is in **`backlog/docs/`**
- Project decisions are in **`backlog/decisions/`**

### üîß **ACTING** (How to change things)

- **All task operations MUST use the Backlog.md CLI tool**
- This ensures metadata is correctly updated and the project stays in sync
- **Always use `--plain` flag** when listing or viewing tasks for AI-friendly text output

---

## 2. Common Mistakes to Avoid

### ‚ùå **WRONG: Direct File Editing**

```markdown
# DON'T DO THIS:
1. Open backlog/tasks/task-7 - Feature.md in editor
2. Change "- [ ]" to "- [x]" manually
3. Add notes directly to the file
4. Save the file
```

### ‚úÖ **CORRECT: Using CLI Commands**

```bash
# DO THIS INSTEAD:
backlog task edit 7 --check-ac 1  # Mark AC #1 as complete
backlog task edit 7 --notes "Implementation complete"  # Add notes
backlog task edit 7 -s "In Progress" -a @agent-k  # Change status and assign
```

---

## 3. Understanding Task Format (Read-Only Reference)

‚ö†Ô∏è **FORMAT REFERENCE ONLY** - Never edit task files directly! Use CLI commands.

### How to Modify Each Section

| What You Want to Change | CLI Command to Use |
|-------------------------|-------------------|
| Title | `backlog task edit 42 -t "New Title"` |
| Status | `backlog task edit 42 -s "In Progress"` |
| Assignee | `backlog task edit 42 -a @sara` |
| Labels | `backlog task edit 42 -l backend,api` |
| Description | `backlog task edit 42 -d "New description"` |
| Add AC | `backlog task edit 42 --ac "New criterion"` |
| Check AC #1 | `backlog task edit 42 --check-ac 1` |
| Uncheck AC #2 | `backlog task edit 42 --uncheck-ac 2` |
| Remove AC #3 | `backlog task edit 42 --remove-ac 3` |
| Add Plan | `backlog task edit 42 --plan "1. Step one\n2. Step two"` |
| Add Notes | `backlog task edit 42 --notes "What I did"` |
| Append Notes | `backlog task edit 42 --append-notes "Another note"` |

---

## 4. Implementing Tasks Workflow

### Step 1: Start Work
```bash
# Assign yourself and set to In Progress
backlog task edit 42 -s "In Progress" -a @myself
```

### Step 2: Create Implementation Plan
```bash
# Think about HOW to solve the task
backlog task edit 42 --plan "1. Research\n2. Implement\n3. Test"
```

### Step 3: Share Plan with User
Share the plan and wait for approval before coding.

### Step 4: Implement
Write code, test, and mark acceptance criteria as complete:
```bash
backlog task edit 42 --check-ac 1 --check-ac 2
```

### Step 5: Add Implementation Notes
```bash
backlog task edit 42 --notes "Implemented using pattern X, modified files Y and Z"
```

### Step 6: Mark as Done
```bash
backlog task edit 42 -s Done
```

---

## 5. Quick Reference: Common Commands

```bash
# List tasks
backlog task list --plain
backlog task list -s "To Do" --plain

# View task
backlog task 42 --plain

# Search
backlog search "auth" --plain

# Create task
backlog task create "Task title" -d "Description" --ac "Criterion 1"

# Edit task
backlog task edit 42 -s "In Progress" -a @myself
backlog task edit 42 --check-ac 1
backlog task edit 42 --notes "Implementation complete"
```

---

## Remember: The Golden Rule

**üéØ If you want to change ANYTHING in a task, use `backlog task edit`**
**üìñ Use CLI to read tasks, exceptionally READ task files directly, never WRITE to them**

Full help: `backlog --help`

<!-- BACKLOG.MD GUIDELINES END -->
